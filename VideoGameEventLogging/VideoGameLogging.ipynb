{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Game Event Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want to spin up my docker containers\n",
    "\n",
    "```{}\n",
    "docker-compose up -d\n",
    "docker-compose ps\n",
    "```\n",
    "\n",
    "If everything goes well, we should have the zookeeer,kafka,cloudera,spark,presto,and mids containers up.\n",
    "\n",
    "```\n",
    "Creating network \"project3mbearwberkeley_default\" with the default driver\n",
    "Creating project3mbearwberkeley_presto_1\n",
    "Creating project3mbearwberkeley_cloudera_1\n",
    "Creating project3mbearwberkeley_zookeeper_1\n",
    "Creating project3mbearwberkeley_mids_1\n",
    "Creating project3mbearwberkeley_kafka_1\n",
    "Creating project3mbearwberkeley_spark_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I want to create a topic called \"events\" where the item purchasing data is published. \n",
    "\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "```\n",
    "\n",
    "Then I want to begin my game.api Flask app\n",
    "\n",
    "\n",
    "```\n",
    "docker-compose exec mids env FLASK_APP=/w205/project-3-mbearw-berkeley/game_api.py flask run --host 0.0.0.0\n",
    "```\n",
    "if done correctly, we should see it run at 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to start kafkacat to see item purchasing in real-time\n",
    "\n",
    "```\n",
    "docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning\n",
    "```\n",
    "it won't return anything at first, but that'll change once users start to purchase items!\n",
    "\n",
    "Since BOTW2 isn't out yet, let's simulate some user action using Apache Bench\n",
    "\n",
    "```\n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword;docker-compose exec mids ab -n 4 -H \"Host: user3.tmobile.com\" http://localhost:5000/purchase_a_blade;docker-compose exec mids ab -n 1 -H \"Host: user3.tmobile.com\" http://localhost:5000/join_mages_guild; sleep 5; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use a Pyspark notebook to filter these records, we have to mount the directory.\n",
    "\n",
    "```\n",
    "docker-compose exec spark bash\n",
    "ln -s /w205 w205\n",
    "exit\n",
    "```\n",
    "\n",
    "now we can open the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.functions import udf, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define our schema and define functions for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purchase_sword_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"description\",StringType(),True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf('boolean')\n",
    "def is_sword_purchase(event_as_json):\n",
    "    \"\"\"udf for filtering events\n",
    "    \"\"\"\n",
    "    event = json.loads(event_as_json)\n",
    "    if (event['event_type'] == 'purchase_sword')|(event['event_type']=='purchase_blade'):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the data from \"events\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_events = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"events\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And filter out sword purchases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sword_purchases = raw_events \\\n",
    "    .filter(is_sword_purchase(raw_events.value.cast('string'))) \\\n",
    "    .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "            raw_events.timestamp.cast('string'),\n",
    "            from_json(raw_events.value.cast('string'),\n",
    "                      purchase_sword_event_schema()).alias('json')) \\\n",
    "    .select('raw_event', 'timestamp', 'json.*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we set up a StreamingQuery so our Hive table can incorporate new data on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = sword_purchases \\\n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoints_for_sword_purchases\") \\\n",
    "    .option(\"path\", \"/tmp/sword_purchases\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink.stop() # this stops the stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out our files in Hadoop\n",
    "\n",
    "```\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases\n",
    "```\n",
    "\n",
    "we should see these two files in there\n",
    "\n",
    "```\n",
    "drwxr-xr-x   - root supergroup          0 2020-12-07 06:49 /tmp/sword_purchases/_spark_metadata\n",
    "-rw-r--r--   1 root supergroup        777 2020-12-07 06:49 /tmp/sword_purchases/part-00000-dc691dfc-cd95-49a2-97dc-a7c4492cd18e-c000.snappy.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create our Hive table and query it with Presto\n",
    "\n",
    "Open Hive\n",
    "```\n",
    "docker-compose exec cloudera hive\n",
    "```\n",
    "and run\n",
    "\n",
    "```\n",
    "create external table if not exists default.sword_purchases (raw_event string, timestamp string,Accept string, Host string, User_Agent string, event_type string ) stored as parquet location '/tmp/sword_purchases'  tblproperties (\"parquet.compress\"=\"SNAPPY\");\n",
    "```\n",
    "which will return \n",
    "\n",
    "```\n",
    "OK\n",
    "Time taken: 0.764 seconds\n",
    "```\n",
    "\n",
    "exit and go to Presto to query the data\n",
    "\n",
    "```\n",
    "exit;\n",
    "\n",
    "docker-compose exec presto presto --server presto:8080 --catalog hive --schema default\n",
    "```\n",
    "I'm interested in what weapons people have bought so far. Let's find out\n",
    "\n",
    "```\n",
    "select distinct (event_type) from sword_purchases;\n",
    "```\n",
    "\n",
    "which returns\n",
    "\n",
    "```\n",
    "   event_type   \n",
    "----------------\n",
    " purchase_sword \n",
    " purchase_blade \n",
    "(2 rows)\n",
    "Query 20201207_065455_00002_xc2rd, FINISHED, 1 node\n",
    "Splits: 35 total, 19 done (54.29%)\n",
    "0:03 [340 rows, 46.2KB] [99 rows/s, 13.6KB/s]\n",
    "```\n",
    "We have 2 types of weapons purchased so far, a sword and a blade. \n",
    "\n",
    "Once we're finished with our table analysis (more weapons to come!) we can close everything down with \n",
    "\n",
    "```\n",
    "docker-compose down\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Looks like we need more weapons for a complete game! \n",
    "\n",
    "This concludes the report~"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
